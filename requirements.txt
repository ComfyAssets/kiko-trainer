# Core FastAPI and web server
fastapi
uvicorn
python-multipart

# Vision-Language Models and ML Core
transformers>=4.51.3  # Required for Qwen2.5-VL support
huggingface_hub
torch
torchvision>=0.23.0
timm
einops
accelerate
tensorboard

# Image processing
Pillow

# Qwen2.5-VL specific utilities
qwen-vl-utils[decord]==0.0.8

# Optional: 4-bit quantization support (saves VRAM)
bitsandbytes

# Utilities
python-slugify
pyyaml

# Async HTTP client for downloads
aiohttp
pydantic
psutil


# Optional: Flash Attention 2 for speed optimization
# Uncomment the line below if you have A100/H100 or compatible GPU
# flash-attn>=2.0.0
